{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import cPickle\n",
    "import time\n",
    "def unpickle(file):\n",
    "    fo = open(file, 'rb')\n",
    "    data = cPickle.load(fo)\n",
    "    fo.close()\n",
    "    return data\n",
    "train_set_1 = unpickle(\"cifar-10-batches-py/data_batch_1\")\n",
    "train_set_2 = unpickle(\"cifar-10-batches-py/data_batch_2\")\n",
    "train_set_3 = unpickle(\"cifar-10-batches-py/data_batch_3\")\n",
    "train_set_4 = unpickle(\"cifar-10-batches-py/data_batch_4\")\n",
    "train_set_5 = unpickle(\"cifar-10-batches-py/data_batch_5\")\n",
    "test_set = unpickle(\"cifar-10-batches-py/test_batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_1=train_set_1['data']\n",
    "Y_train_1=train_set_1['labels']\n",
    "\n",
    "X_train_2=train_set_2['data']\n",
    "Y_train_2=train_set_2['labels']\n",
    "\n",
    "X_train_3=train_set_3['data']\n",
    "Y_train_3=train_set_3['labels']\n",
    "\n",
    "X_train_4=train_set_4['data']\n",
    "Y_train_4=train_set_4['labels']\n",
    "\n",
    "X_test=test_set['data']\n",
    "Y_test=test_set['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train=np.concatenate((X_train_1,X_train_2,X_train_3,X_train_4),axis=0)\n",
    "Y_train=np.concatenate((Y_train_1,Y_train_2,Y_train_3,Y_train_4),axis=0)\n",
    "X_train=X_train.reshape(40000,3,32,32)\n",
    "X_test=X_test.reshape(10000,3,32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the X_train  (40000, 3, 32, 32)\n",
      "shape of the X_test  (10000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "print \"length of the X_train \",X_train.shape\n",
    "print \"shape of the X_test \",X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this version,\n",
    "i want to change the way how did i div the image.\n",
    "I will do the things that the artical said."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = 6\n",
    "K=1600\n",
    "whitening=True\n",
    "nb_patch = 200000\n",
    "CIFAR_DIM=[32,32,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def collect_random_patch(X_train):\n",
    "    train_patches=[]\n",
    "    for i in range(nb_patch):\n",
    "        m=random.randint(0,32-w)\n",
    "        n=random.randint(0,32-w)\n",
    "        patch=np.array([])\n",
    "        image=X_train[i%(len(X_train))]\n",
    "        for layer in image:\n",
    "            patch=np.append(patch,layer[m:m+w].T[n:n+w].T.ravel())\n",
    "        train_patches.append(patch)\n",
    "    train_patches=np.asarray(train_patches)\n",
    "    return train_patches\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the train_patches  (200000, 108)\n"
     ]
    }
   ],
   "source": [
    "train_patches=collect_random_patch(X_train)\n",
    "print \"shape of the train_patches \",train_patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing the train patches...\n"
     ]
    }
   ],
   "source": [
    "print \"normalizing the train patches...\"\n",
    "train_patches=(train_patches-train_patches.mean(1)[:,None])/np.sqrt(train_patches.var(1)+10)[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whitening the train patches... \n",
      "end of whitening\n"
     ]
    }
   ],
   "source": [
    "print \"whitening the train patches... \"\n",
    "[D,V]=np.linalg.eig(np.cov(train_patches,rowvar=0))\n",
    "\n",
    "P = V.dot(np.diag(np.sqrt(1/(D + 0.1)))).dot(V.T)\n",
    "train_patches = train_patches.dot(P)\n",
    "print \"end of whitening\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start creating the dictionary\n",
      "Start using the sklearn Kmeans....\n",
      "K-means has done...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans \n",
    "K=800\n",
    "print \"Start creating the dictionary\"\n",
    "print \"Start using the sklearn Kmeans....\"\n",
    "result = KMeans(n_clusters=K,max_iter=50).fit(train_patches)\n",
    "print \"K-means has done...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "centroids  (800, 108)\n"
     ]
    }
   ],
   "source": [
    "centroids=result.cluster_centers_\n",
    "print \"centroids \",centroids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "def sliding(img,window=[6,6]):\n",
    "    out=np.array([])\n",
    "    for i in range(3):\n",
    "        row=32\n",
    "        col=32\n",
    "        col_extent = col - window[1] + 1\n",
    "        row_extent = row - window[0] + 1\n",
    "        start_idx = np.arange(window[0])[:,None]*col + np.arange(window[1])\n",
    "        offset_idx = np.arange(row_extent)[:,None]*col + np.arange(col_extent)\n",
    "        if len(out)==0:\n",
    "            out=np.take (img[i],start_idx.ravel()[:,None] + offset_idx.ravel())\n",
    "        else:\n",
    "            out=np.append(out,np.take (img[i],start_idx.ravel()[:,None] + offset_idx.ravel()),axis=0)\n",
    "    return out\n",
    "\n",
    "\n",
    "def extract_features_soft(X_train):\n",
    "    trainXC=[]\n",
    "    idx=0\n",
    "    for img in X_train:\n",
    "        idx+=1\n",
    "        \n",
    "        if (idx%1000==0):\n",
    "            print idx,'/',len(X_train)\n",
    "        \n",
    "        patches=sliding(img,[w,w]).T\n",
    "        patches=(patches-patches.mean(1)[:,None])/(np.sqrt(patches.var(1)+10)[:,None])\n",
    "        patches=patches.dot(P)\n",
    "        \n",
    "        x2=np.power(patches,2).sum(1)\n",
    "        c2=np.power(centroids,2).sum(1)\n",
    "        xc=patches.dot(centroids.T)\n",
    "\n",
    "        dist=np.sqrt(-2*xc+x2[:,None]+c2)\n",
    "        u=dist.mean(1)\n",
    "        patches=np.maximum(-dist+u[:,None],0)\n",
    "        rs=CIFAR_DIM[0]-w+1\n",
    "        cs=CIFAR_DIM[1]-w+1\n",
    "        patches=np.reshape(patches,[rs,cs,-1])\n",
    "        q=[]\n",
    "        q.append(patches[0:rs/2,0:cs/2].sum(0).sum(0))\n",
    "        q.append(patches[0:rs/2,cs/2:cs-1].sum(0).sum(0))\n",
    "        q.append(patches[rs/2:rs-1,0:cs/2].sum(0).sum(0))\n",
    "        q.append(patches[rs/2:rs-1,cs/2:cs-1].sum(0).sum(0))\n",
    "        q=np.array(q).ravel()\n",
    "        trainXC.append(q)\n",
    "    trainXC=np.array(trainXC)\n",
    "    trainXC=(trainXC-trainXC.mean(1)[:,None])/(np.sqrt(trainXC.var(1)+0.01)[:,None])\n",
    "    return trainXC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start creating the soft dictionary\n",
      "1000 / 20000\n",
      "2000 / 20000\n",
      "3000 / 20000\n",
      "4000 / 20000\n",
      "5000 / 20000\n",
      "6000 / 20000\n",
      "7000 / 20000\n",
      "8000 / 20000\n",
      "9000 / 20000\n",
      "10000 / 20000\n",
      "11000 / 20000\n",
      "12000 / 20000\n",
      "13000 / 20000\n",
      "14000 / 20000\n",
      "15000 / 20000\n",
      "16000 / 20000\n",
      "17000 / 20000\n",
      "18000 / 20000\n",
      "19000 / 20000\n",
      "20000 / 20000\n",
      "trainXC compelted\n"
     ]
    }
   ],
   "source": [
    "print \"start creating the soft dictionary\"\n",
    "trainXC=extract_features_soft(X_train[0:20000])\n",
    "print \"trainXC compelted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start creating the soft dictionary\n",
      "1000 / 10000\n",
      "2000 / 10000\n",
      "3000 / 10000\n",
      "4000 / 10000\n",
      "5000 / 10000\n",
      "6000 / 10000\n",
      "7000 / 10000\n",
      "8000 / 10000\n",
      "9000 / 10000\n",
      "10000 / 10000\n",
      "testXC compelted\n"
     ]
    }
   ],
   "source": [
    "print \"start creating the soft dictionary\"\n",
    "testXC=extract_features_soft(X_test)\n",
    "print \"testXC compelted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainXC  (20000, 3200)\n",
      "test XC (10000, 3200)\n"
     ]
    }
   ],
   "source": [
    "print \"trainXC \",trainXC.shape\n",
    "print \"test XC\",testXC.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the right input, we could choose to our own classify model or could just choose the keras to do this work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using the triangle dictionary for K-means\n",
      "using the SVC to do the classification:\n",
      "model compeleted\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "print \"using the triangle dictionary for K-means\"\n",
    "print \"using the SVC to do the classification:\"\n",
    "model=SVC()\n",
    "model=model.fit(trainXC,Y_train[0:20000])\n",
    "\n",
    "print \"model compeleted\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6049\n"
     ]
    }
   ],
   "source": [
    "print model.score(testXC,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features_hard(X_train):\n",
    "    trainXC=[]\n",
    "    idx=0\n",
    "    for img in X_train:\n",
    "        idx+=1\n",
    "        \n",
    "        patches=sliding(img,[w,w]).T\n",
    "\n",
    "        patches=(patches-patches.mean(1)[:,None])/(np.sqrt(patches.var(1)+10)[:,None])\n",
    "        patches=patches.dot(P)\n",
    "        \n",
    "        pre_index=result.predict(patches)\n",
    "        dict_patches=np.zeros(shape=(len(patches),K))\n",
    "        \n",
    "        for i in range(len(patches)):\n",
    "            predict_index=pre_index[i]\n",
    "            dict_patches[i][pre_index]=1\n",
    "        \n",
    "        rs=CIFAR_DIM[0]-w+1\n",
    "        cs=CIFAR_DIM[1]-w+1\n",
    "        dict_patches=np.reshape(dict_patches,[rs,cs,-1])\n",
    "        q=[]\n",
    "        q.append(dict_patches[0:rs/2,0:cs/2].sum(0).sum(0))\n",
    "        q.append(dict_patches[0:rs/2,cs/2:cs-1].sum(0).sum(0))\n",
    "        q.append(dict_patches[rs/2:rs-1,0:cs/2].sum(0).sum(0))\n",
    "        q.append(dict_patches[rs/2:rs-1,cs/2:cs-1].sum(0).sum(0))\n",
    "        q=np.array(q).ravel()\n",
    "        trainXC.append(q)\n",
    "    trainXC=np.array(trainXC)\n",
    "    trainXC=(trainXC-trainXC.mean(1)[:,None])/(np.sqrt(trainXC.var(1)+0.01)[:,None])\n",
    "    return trainXC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainXC_hard compelted\n",
      "trainXC_hard  (20000, 3200)\n",
      "testXC_hard compelted\n",
      "testXC_hard  (10000, 3200)\n"
     ]
    }
   ],
   "source": [
    "trainXC_hard=extract_features_hard(X_train[0:20000])\n",
    "print \"trainXC_hard compelted\"\n",
    "print \"trainXC_hard \",trainXC_hard.shape\n",
    "testXC_hard=extract_features_hard(X_test)\n",
    "print \"testXC_hard compelted\"\n",
    "print \"testXC_hard \",testXC_hard.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using the K-means hard\n",
      "using the SVC to do the classification: \n",
      "model compeleted\n",
      "0.5905\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "print \"using the K-means hard\"\n",
    "print \"using the SVC to do the classification: \"\n",
    "model=SVC()\n",
    "model=model.fit(trainXC_hard,Y_train[0:20000])\n",
    "\n",
    "print \"model compeleted\"\n",
    "print model.score(testXC_hard,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
